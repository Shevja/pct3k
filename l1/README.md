Практическая работа 1
    
    Требуется на базе операций MPI_Send, MPI_Recv, MPI_Sendrecv, MPI_Isend, MPI_Irecv реализовать 
    следующие схемы обменов:
    1)Кольцо (ring)
        Каждый процесс i передает сообщение процессу i+1 и принимает сообщение от процесса i-1.  
        Получив сообщение процесс передает его дальше по кольцу (на следующем шаге). Обмены выполняются до тех пор,
        пока через каждый процесс не пройдут все сообщения.
        Таким образом каждый процесс выполнит p-1 раз операцию передачи (и приема соответственно). Измерить время 
        выполнения обменов в процессе 0 при следующих размерах сообщений:
            m = 1 B (count = 1, datatype = MPI_CHAR)
            m = 1 KB (count = 1024, datatype = MPI_CHAR)
            m = 1 MB (count = 1024 * 1024, datatype = MPI_CHAR)
            
        Замеры выполнить на подсистемах следующих конфигураций:
            16 процессов: 2 узла по 8 ядер
            16 процессов: 4 узла по 4 ядра
            16 процессов: 8 узлов по 2 ядра
        
        Время измерять функцией MPI_Wtime, результаты записывать в отчет (текстовый файл).

    2)Broadcast (трансляционная передача, one-to-all)
        Корневой процесс 0 последовательно передает свое сообщение из буфера sbuf в буфер rbuf процессов 0, 1, 2,...p-1.
        Оценить время выполнения обменов в процессах 0, 1,...p-1 при следующих размерах сообщений:
            m = 1 KB (count = 1024, datatype = MPI_CHAR)
            m = 1 MB (count = 1024 * 1024, datatype = MPI_CHAR)
        
        Определить все ли процессы завершают обмены в один момент времени. Замеры выполнить на подсистемах следующих 
        конфигураций:
            32 процесса: 4 узла по 8 ядер
            32 процесса: 8 узлов по 4 ядра
    
    3)Gather (коллекторный прием, all-to-one)
        Корневой процесс 0 принимает сообщения из буфера sbuf процессов 0, 1, 2,...p-1 в свой буфер rbuf. Длина буфера 
        rbuf в корневом процессе равна сумме размеров буферов sbuf всех процессов. Оценить время выполнения обменов в 
        процессах 0, 1,...p-1 при следующих размерах сообщений:
            m = 1 KB (count = 1024, datatype = MPI_CHAR)
            m = 1 MB (count = 1048576, datatype = MPI_CHAR)

        Определить все ли процессы завершают обмены в один момент времени. Замеры выполнить на подсистемах следующих конфигураций:
            32 процесса: 4 узла по 8 ядер
            32 процесса: 8 узлов по 4 ядра

    4)All-to-all
        Каждый процесс передает свое сообщение всем процессам. Для реализации обменов использовать неблокирующие  
        функции MPI_Isend, MPI_Irecv и MPI_Waitall. Оценить время выполнения обменов(при count = 1024, datatype  =  MPI_CHAR) на подсистемах следующихконфигураций:
            32 процесса: 4 узла по 8 ядер
            32 процесса: 8 узлов по 4 ядра